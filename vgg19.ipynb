{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"},"kaggle":{"accelerator":"none","dataSources":[],"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nimport torchvision.models as models\nfrom torchvision.transforms import transforms\nfrom torch.utils.data import Dataset, DataLoader\nfrom PIL import Image\nfrom sklearn.preprocessing import LabelEncoder\nimport matplotlib.pyplot as plt\nfrom sklearn.model_selection import train_test_split\n\n\n# Define the directory containing the objects images\nobjects_dir = '/kaggle/input/dl-dataset/DL Dataset'\n\n# Define the list of target objects classes\nclasses = ['beds', 'bikes', 'cars', 'cats', 'chair', 'cycle', 'dogs', 'flowers', 'horses', 'person']\n\naccuracy_values = []\nloss_values = []\n# Define the transformation to apply to the images\ntransform = transforms.Compose([\n    transforms.Resize((224, 224)),\n    transforms.ToTensor(),\n    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n])\n\n# Custom dataset class for loading the objects images\nclass ObjectDataset(Dataset):\n    def __init__(self, objects_dir, classes, transform=None):\n        self.objects_dir = objects_dir\n        self.classes = classes\n        self.transform = transform\n        self.image_files = []\n        self.labels = []\n\n        # Initialize label encoder\n        self.label_encoder = LabelEncoder()\n        self.label_encoder.fit(classes)\n\n        # Iterate over each class folder\n        for classe in classes:\n            classe_dir = os.path.join(objects_dir, classe)\n            if os.path.isdir(classe_dir):\n                files = os.listdir(classe_dir)\n                self.image_files.extend(files)\n                self.labels.extend([classe] * len(files))\n\n    def __len__(self):\n        return len(self.image_files)\n\n    def __getitem__(self, idx):\n        img_path = os.path.join(self.objects_dir, self.labels[idx], self.image_files[idx])\n        image = Image.open(img_path).convert('RGB')\n        if self.transform:\n            image = self.transform(image)\n\n        label = self.labels[idx]\n        label = self.label_encoder.transform([label])[0]\n\n        return image, label\n\n\n# Create the dataset\ndataset = ObjectDataset(objects_dir, classes, transform=transform)\n\n# Split the dataset into training and testing sets\ntrain_dataset, test_dataset = train_test_split(dataset, test_size=0.2, random_state=42)\n\n# Create the dataloaders for training and testing\ntrain_dataloader = DataLoader(train_dataset, batch_size=32, shuffle=True)\ntest_dataloader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n\n# Modify the last fully connected layer for the number of classes\nnum_classes = len(classes)\n\n# Define the custom VGG16-like model\nclass CustomVGG16(nn.Module):\n    def __init__(self, num_classes):\n        super(CustomVGG16, self).__init__()\n        self.features = nn.Sequential(\n            nn.Conv2d(3, 64, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.Conv2d(64, 64, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n            nn.Conv2d(64, 128, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.Conv2d(128, 128, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n            nn.Conv2d(128, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.Conv2d(256, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.Conv2d(256, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.Conv2d(256, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n            nn.Conv2d(256, 512, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.Conv2d(512, 512, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.Conv2d(512, 512, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.Conv2d(512, 512, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n            nn.Conv2d(512, 512, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.Conv2d(512, 512, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.Conv2d(512, 512, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.Conv2d(512, 512, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2)\n        )\n        self.avgpool = nn.AdaptiveAvgPool2d((7, 7))\n        self.classifier = nn.Sequential(\n            nn.Linear(512 * 7 * 7, 4096),\n            nn.ReLU(inplace=True),\n            nn.Dropout(),\n            nn.Linear(4096, 4096),\n            nn.ReLU(inplace=True),\n            nn.Dropout(),\n            nn.Linear(4096, num_classes)\n        )\n\n    def forward(self, x):\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# Create an instance of the custom VGG16-like model\nmodel = CustomVGG16(num_classes)\n\n\n# Define the loss function and optimizer\ncriterion = nn.CrossEntropyLoss()\noptimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n\n# Train the model\nnum_epochs = 20\nfor epoch in range(num_epochs):\n    running_loss = 0.0\n    correct_predictions = 0\n    total_predictions = 0\n\n    for images, labels in train_dataloader:\n        optimizer.zero_grad()\n        outputs = model(images)\n        loss = criterion(outputs, labels)\n        loss.backward()\n        optimizer.step()\n\n        # Track the loss\n        running_loss += loss.item() * images.size(0)\n\n        # Track the accuracy\n        _, predicted_labels = torch.max(outputs.data, 1)\n        total_predictions += labels.size(0)\n        correct_predictions += (predicted_labels == labels).sum().item()\n\n    epoch_loss = running_loss / len(dataset)\n    epoch_accuracy = (correct_predictions / total_predictions) * 100\n\n    accuracy_values.append(epoch_accuracy)\n    loss_values.append(epoch_loss)\n\n\n    print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {epoch_loss:.4f}, Accuracy: {epoch_accuracy:.2f}%\")\n\nplt.plot(range(1, num_epochs+1), accuracy_values)\nplt.xlabel('Epoch')\nplt.ylabel('Accuracy')\nplt.title('Accuracy vs Epochs')\nplt.show()\n\n\nplt.plot(range(1, num_epochs+1), loss_values)\nplt.xlabel('Epoch')\nplt.ylabel('Loss')\nplt.title('Loss vs Epochs')\nplt.show()\n\n\n# Save the trained model\ntorch.save(model.state_dict(), '/kaggle/input/dl-model-path/DL/model.pth')\n\n\n\nimport numpy as np\nmodel.eval()\n\n# Load and preprocess the input image\ninput_image_path = '/kaggle/input/testing-dataset/testing/chair_test.jpg'  # Replace with the path to your input image\ninput_image = Image.open(input_image_path).convert('RGB')\ninput_image_transformed = transform(input_image)\ninput_image_tensor = input_image_transformed.unsqueeze(0)  # Add an extra dimension for batch size\n\n# Perform classification\nwith torch.no_grad():\n    output = model(input_image_tensor)\n    predicted_labels = torch.argmax(output, dim=1)\n    predicted_class = classes[predicted_labels.item()]\n    confidence = torch.softmax(output, dim=1)[0, predicted_labels].item() * 100\n\n# Print the predicted class and confidence\nprint(f\"Predicted Class: {predicted_class}\")\nprint(f\"Confidence: {confidence:.2f}%\")\n\n# Display the testing picture with the predicted class\nplt.imshow(np.transpose(input_image_transformed, (1, 2, 0)))\nplt.axis('off')\nplt.title(f'Testing Picture\\nPredicted Class: {predicted_class}', fontsize=12)\nplt.show()\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]}]}